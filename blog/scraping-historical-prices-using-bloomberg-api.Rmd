---
title: Scraping Historical Prices using Bloomberg API
author: Rey Anthony Masilang
date: '2017-05-17'
slug: scraping-historical-prices-using-bloomberg-api
categories:
  - Scraping
  - Finance
  - R
tags:
  - web scraping
  - ggiraph
  - ggplot2
  - UITF
  - API
banner: 'img/banners/scrape_API_banner.png'
description: ''
images: []
menu: ''
output: blogdown::html_page
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE)
```

## Introduction

This post is a soft update to my previous post on [Exploring UITFs in the Philippines](https://r-mas.github.io/blog/2017/05/15/exploring-uitfs-in-the-philippines/). One limitation of that study is that the historical prices used were limited to the past 12 months only. In this post, I'm going to share how to scrape up to 5 years worth of historical prices from [Bloomberg.com](https://www.bloomberg.com).  


## Bloomberg "bulk-time-series" API

I owe a big thanks to [this wonderful article](http://www.gregreda.com/2015/02/15/web-scraping-finding-the-api/) on finding the API by Greg Reda. By following his instructions, I was able to find the API used in constructing the charts in Bloomberg quote pages like [this one](https://www.bloomberg.com/quote/PCOMP:IND). The API is very simple to use. You just need to execute a request URL in your browser and it returns the data for your query in JSON format. The request URL goes like this:

- **www.bloomberg.com/markets/api/bulk-time-series/price/**`<symbol>`**?timeFrame=**`<time frame>`

The `<symbol>` placeholder should be replaced with the stock ticker symbol you want. Example is `PCOMP:IND` for the Philippine Stock Exchange Index. Then the `<time frame>` can be either of the following:

- `1_DAY`
- `1_MONTH`
- `1_YEAR`
- `5_YEAR`

Click on the example below to view the 5-year historical price data for the PSE index in your browser.

- [www.bloomberg.com/markets/api/bulk-time-series/price/PCOMP:IND?timeFrame=5_YEAR](https://www.bloomberg.com/markets/api/bulk-time-series/price/PCOMP:IND?timeFrame=5_YEAR)

Scraping data through APIs makes it very easy to get historical price data for many stock symbols at once. I wrote a simple R function that gets this data in JSON format and parses it into a list containing a list of metadata and a prices data frame.

```{r sample_function}
get_bloomberg_prices <- function(symbol, time_frame) {
    
    require(rjson)
    require(dplyr)
    
    url <- paste0("https://www.bloomberg.com/markets/api/bulk-time-series/price/",
                  symbol, "?timeFrame=", time_frame)
    json_data <- fromJSON(file = url)[[1]]
    metadata <- json_data[-(2:3)]
    prices <- json_data[3] %>% 
        unlist() %>% 
        matrix(ncol = 2, byrow = TRUE, 
               dimnames = list(c(), c("Date", "Value"))) %>% 
        as_data_frame()  %>% 
        mutate(Value = as.numeric(Value))
    
    list(metadata = metadata, prices = prices)
}
```


## A Quick Example

We can use the `get_bloomberg_prices()` function to quickly parse data for UITFs in the Philippines and quickly compare their performances in the past 5 years. We'll use the `uitf_matrix` dataset produced in my [previous post](https://r-mas.github.io/blog/2017/05/07/scraping-web-data-on-uitfs-using-r/).

```{r load_data, warning=F, message=F, echo=F}
require(readr)
require(dplyr)

uitf_matrix <- read_csv("D:/Rey/Projects/Github/ph_uitf/Datasets/uitf_matrix_05_07_2017.csv") %>% 
    mutate(`Fund Classification` = factor(`Fund Classification`,
                                          levels = c("Money Market Funds",
                                                     "Medium Term Bond Funds",
                                                     "Intermediate Term Bond Funds",
                                                     "Long Term Bond Funds",
                                                     "Balanced Funds",
                                                     "Equity Funds"))) %>% 
    mutate(tooltip = paste(Name,
                           paste("Symbol:", Symbol),
                           paste("Bank:", Bank),
                           paste("Classification:", 
                                 `Fund Classification`),
                           sep = "\n"))

```

```{r load_data_display, warning=F, message=F, eval=F}
require(readr)
uitf_matrix <- read_csv("https://raw.githubusercontent.com/r-mas/ph_uitf/master/Datasets/uitf_matrix_05_07_2017.csv")

```

This dataset contains information on `r nrow(uitf_matrix)` UITFs in the Philippines. We'll need the `Symbol` column from this data frame.

```{r scrape_chunk, warning=F, message=F, eval=F}
require(dplyr)
require(lubridate)

# initialize empty data frame
price_data <- data_frame(Symbol = character(),
                         Date = as.Date(vector()),
                         Value = double())
# scrape data
for(i in 1:nrow(uitf_matrix)) {
    raw_data <- get_bloomberg_prices(symbol = uitf_matrix$Symbol[i],
                                     time_frame = "5_YEAR")
    
    processed <- raw_data$prices %>% 
        mutate(Date = ymd(Date)) %>% 
        mutate(Symbol = raw_data[["metadata"]][["id"]]) %>% 
        select(Symbol, Date, Value) %>% 
        distinct()
    
    price_data <- bind_rows(price_data, processed)
}

```

```{r load_price_data, warning=F, message=F, echo=F}

price_data <- read_csv("D:/Rey/Projects/Github/ph_uitf/Datasets/price_data_05_17_2017")

```


A little more processing and we can overlay the prices for all UITFs to compare performances.

```{r display_chart_chunk, warning=F, message=F}
require(dplyr)
require(ggplot2)
require(ggiraph)

plot <- price_data %>% 
    arrange(Symbol, Date) %>% 
    group_by(Symbol) %>% 
    mutate(Return = 100*(Value/first(Value)-1)) %>% 
    mutate(Return_5Y = 100*(last(Value)/first(Value)-1)) %>% 
    ungroup() %>%
    left_join(uitf_matrix[, c("Symbol", "Name", "Bank", "Fund Classification", "tooltip")]) %>% 
    mutate(tooltip = paste(tooltip, 
                           paste0("5Y-Return: ", 
                                  formatC(Return_5Y, format = "f", digits = 2),
                                 "%"),
                           sep = "\n")) %>% 
    ggplot(aes(x = Date, y = Return, col = Symbol)) +
    geom_line_interactive(aes(data_id = Symbol, tooltip = tooltip)) +
    facet_wrap(~`Fund Classification`, ncol = 1, scales = "free_y") +
    theme(legend.position = "none")

ggiraph(ggobj = plot, height_svg = 20, width_svg = 9, width = 1,
        hover_css = "stroke:black; stroke-width:2")

```


## Final Notes

Scraping web data using APIs is very efficient. We were able to easily gather historical price data for `r nrow(uitf_matrix)` UITFs using the method described above. This method can generalize to basically any type of dataset we wish to gather as long as an API exists for that.






<br /><br /><br /><br />

